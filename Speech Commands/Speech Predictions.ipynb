{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301cb0eb",
   "metadata": {},
   "source": [
    "<h1 style = \"font-size:3rem;color:darkcyan\"> Make Speech Predictions</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c0d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "89727c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Keyword_Recognition:\n",
    "    \n",
    "    def __init__(self, model_path, sample_rate = 22500, audio_dur = 1, hop_length = 512, n_mfcc = 13, n_fft = 2048):\n",
    "    \n",
    "        self.model = keras.models.load_model(model_path)\n",
    "        \n",
    "        self.mappings = [\n",
    "            \"backward\",\n",
    "            \"bed\",\n",
    "            \"bird\",\n",
    "            \"cat\",\n",
    "            \"dog\",\n",
    "            \"down\",\n",
    "            \"eight\",\n",
    "            \"five\",\n",
    "            \"follow\",\n",
    "            \"forward\",\n",
    "            \"four\",\n",
    "            \"go\",\n",
    "            \"happy\",\n",
    "            \"house\",\n",
    "            \"learn\",\n",
    "            \"left\",\n",
    "            \"marvin\",\n",
    "            \"nine\",\n",
    "            \"no\",\n",
    "            \"off\",\n",
    "            \"on\",\n",
    "            \"one\",\n",
    "            \"right\",\n",
    "            \"seven\",\n",
    "            \"sheila\",\n",
    "            \"six\",\n",
    "            \"stop\",\n",
    "            \"three\",\n",
    "            \"tree\",\n",
    "            \"two\",\n",
    "            \"up\",\n",
    "            \"visual\",\n",
    "            \"wow\",\n",
    "            \"yes\",\n",
    "            \"zero\"\n",
    "        ]\n",
    "        \n",
    "        self.n_samples = int(audio_dur * sample_rate)\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "\n",
    "    def _preprocess(self, file_path):\n",
    "        audio_data, _ = librosa.load(file_path, sr= self.sample_rate, mono=True)\n",
    "        \n",
    "        # zero pad signal if needed to ensure even lengths\n",
    "        if len(audio_data) < self.n_samples:\n",
    "            zero_pad = np.zeros(self.n_samples - len(audio_data))\n",
    "            audio_data = np.append(audio_data, zero_pad)\n",
    "            \n",
    "        # crop audio when larger\n",
    "        if len(audio_data > self.n_samples):\n",
    "            audio_data = audio_data[:self.n_samples] \n",
    "\n",
    "        # extract the MFCC\n",
    "        mfcc = librosa.feature.mfcc(y = audio_data, \n",
    "                                            sr = self.sample_rate, \n",
    "                                            n_mfcc = self.n_mfcc, \n",
    "                                            n_fft = self.n_fft, \n",
    "                                            hop_length = self.hop_length)\n",
    "\n",
    "        return mfcc.T\n",
    "        \n",
    "    def predict(self, file_path):\n",
    "        \n",
    "        # extract MFCCs\n",
    "        MFCCs = self._preprocess(file_path)\n",
    "        \n",
    "        # add axis for CNN network\n",
    "        MFCCs = MFCCs[np.newaxis, ..., np.newaxis]\n",
    "        \n",
    "        \n",
    "        # make prediction\n",
    "        y_pred = self.model.predict(MFCCs)\n",
    "\n",
    "        # get index of higest probability\n",
    "        pred_class = np.argmax(y_pred, axis=1)\n",
    "        \n",
    "        # print the label\n",
    "        print('The predicted keyword = {}'.format(self.mappings[int(pred_class)]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "00f56c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keyword_recognition = Keyword_Recognition(model_path = 'model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "51de2f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step\n",
      "The predicted keyword = zero\n"
     ]
    }
   ],
   "source": [
    "audio_file_path = '../../../Datasets/Speech/Digits/AudioMNIST/data/04/0_04_49.wav'\n",
    "keyword_recognition.predict(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d43f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
