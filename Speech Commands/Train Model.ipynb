{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3556e8d7",
   "metadata": {},
   "source": [
    "<h1 style = \"font-size:3rem;color:darkcyan\"> Train Classifier</h1>\n",
    "\n",
    "Using TensorFlow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0fe2845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3513121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "def import_dataset(dataset_path):\n",
    "    with open(dataset_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    # split data\n",
    "    \n",
    "    # split list into different np arrays\n",
    "    mappings = np.array(data['mappings']) \n",
    "    inputs = np.array(data['MFCC'])\n",
    "    targets = np.array(data['labels'])\n",
    "    filenames = np.array(data['filenames'])\n",
    "    \n",
    "    return mappings, inputs, targets, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c313319",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings, inputs, targets, filenames = import_dataset('data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "228f0967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape before: (95394, 44, 13)\n",
      "input shape after: (95394, 44, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "# adjusting the input shape for CNN compatibility (from 2D to 3D (excluding # samples))\n",
    "print('input shape before: {}'.format(inputs.shape))\n",
    "inputs = inputs[..., np.newaxis] \n",
    "print('input shape after: {}'.format(inputs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "844e0290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into train, validation, and testing sets\n",
    "# filenames for misclassification-tracking\n",
    "\n",
    "def train_validation_test_split(x, y, filenames, test_size = 0.25, val_size = 0.2):\n",
    "    if (0 < test_size < 1)  and (0 < val_size < 1):\n",
    "        train_size = 1 - test_size - val_size\n",
    "        if train_size > 0:\n",
    "\n",
    "            # train test split\n",
    "            (\n",
    "            x_train, x_test, \n",
    "            y_train, y_test,\n",
    "            fn_train, fn_test\n",
    "            ) = train_test_split(x, y, filenames, test_size = test_size)\n",
    "\n",
    "            #train validation split\n",
    "            (\n",
    "            x_train, x_val, \n",
    "            y_train, y_val, \n",
    "            fn_train, fn_val\n",
    "            ) = train_test_split(x_train, y_train, fn_train, test_size = val_size)\n",
    "\n",
    "            return x_train, x_val, x_test, y_train, y_val, y_test, fn_train, fn_val, fn_test\n",
    "        else: \n",
    "            print('train size is too small, adjust test and validation sizes')\n",
    "            return\n",
    "    else:\n",
    "        print('test and validation size should be between 0 and 1!')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ca8072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, validation and test sets\n",
    "(\n",
    "x_train, x_val, x_test,\n",
    "y_train, y_val, y_test,\n",
    "fn_train, fn_val, fn_test\n",
    ") = train_validation_test_split(inputs, targets, filenames, test_size = 0.25, val_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7752d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57236, 44, 13, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71961c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data.json'\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# split data into train, validation, and test\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test = get_data_split(DATA_PATH)\n",
    "\n",
    "# build model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3] ) #( # segments (sr/hop_size), # n_mfcc, 1)\n",
    "model = build_model(input_shape, LEARNING_RATE, )\n",
    "\n",
    "# train model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
