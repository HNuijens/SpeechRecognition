{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02700ddf",
   "metadata": {},
   "source": [
    "<h1 style = \"font-size:3rem;color:darkcyan\"> Preprocessing Data</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "521e645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "91b74635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "root = '../../../Datasets/Speech/Speech Commands/'\n",
    "sample_rate = 22050\n",
    "n_samples = sample_rate\n",
    "hop_length = 512\n",
    "n_fft = 2048\n",
    "n_mfcc = 13 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "02c823e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing folder 1 out of 35\n",
      "processing folder 2 out of 35\n",
      "processing folder 3 out of 35\n",
      "processing folder 4 out of 35\n",
      "processing folder 5 out of 35\n",
      "processing folder 6 out of 35\n",
      "processing folder 7 out of 35\n",
      "processing folder 8 out of 35\n",
      "processing folder 9 out of 35\n",
      "processing folder 10 out of 35\n",
      "processing folder 11 out of 35\n",
      "processing folder 12 out of 35\n",
      "processing folder 13 out of 35\n",
      "processing folder 14 out of 35\n",
      "processing folder 15 out of 35\n",
      "processing folder 16 out of 35\n",
      "processing folder 17 out of 35\n",
      "processing folder 18 out of 35\n",
      "processing folder 19 out of 35\n",
      "processing folder 20 out of 35\n",
      "processing folder 21 out of 35\n",
      "processing folder 22 out of 35\n",
      "processing folder 23 out of 35\n",
      "processing folder 24 out of 35\n",
      "processing folder 25 out of 35\n",
      "processing folder 26 out of 35\n",
      "processing folder 27 out of 35\n",
      "processing folder 28 out of 35\n",
      "processing folder 29 out of 35\n",
      "processing folder 30 out of 35\n",
      "processing folder 31 out of 35\n",
      "processing folder 32 out of 35\n",
      "processing folder 33 out of 35\n",
      "processing folder 34 out of 35\n",
      "processing folder 35 out of 35\n"
     ]
    }
   ],
   "source": [
    " # data dictionary \n",
    "data  = {\n",
    "    'mappings' : [],  # corresponding word\n",
    "    'labels' : [],    # corresponding number\n",
    "    'MFCC' : [],      # extracted mfcc\n",
    "    'filenames' : []  # original filenames\n",
    " }\n",
    "\n",
    "# go trough all sub folders\n",
    "n_folders = len(os.listdir(root))\n",
    "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(root)):\n",
    "    # skip root dir\n",
    "    if dirpath is not root:\n",
    "        print(f'processing folder {i} out of {n_folders}')\n",
    "        \n",
    "        # extract and append \n",
    "        category = dirpath.split('/')[-1] # last index in list when split\n",
    "        data['mappings'].append(category)\n",
    "\n",
    "        for file in filenames:\n",
    "            file_path = os.path.join(dirpath + '/' + file)\n",
    "            audio_data, _ = librosa.load(file_path, sr= sample_rate, mono=True)\n",
    "\n",
    "            # ignore < 1 sec of audio\n",
    "            if len(audio_data) >= n_samples:\n",
    "\n",
    "                # crop audio when larger\n",
    "                if len(audio_data > n_samples):\n",
    "                    audio_data = audio_data[:n_samples] \n",
    "\n",
    "                # extract the MFCC\n",
    "                mfcc = librosa.feature.mfcc(y = audio_data, \n",
    "                                                    sr = sample_rate, \n",
    "                                                    n_mfcc = n_mfcc, \n",
    "                                                    n_fft = 2048, \n",
    "                                                    hop_length = hop_length)\n",
    "\n",
    "                # store data\n",
    "                data['labels'].append(i-1)\n",
    "                data['MFCC'].append(mfcc.T.tolist())\n",
    "                data['filenames'].append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "15dc7d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to json file \n",
    "json_path = 'data.json'\n",
    "with open(json_path, 'w') as fp:\n",
    "    json.dump(data, fp, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74120f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
